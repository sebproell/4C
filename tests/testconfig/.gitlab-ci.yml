#-------------------------------------------------------------------------------
# General rules when to create a pipeline
# N.B. This doesn't say anything about which jobs are run but only determines
# if a pipeline is created.
workflow:
  name: $FOUR_C_PIPELINE_NAME
  rules:
    # for merge requests
    - if: $CI_MERGE_REQUEST_IID
      variables:
        FOUR_C_PIPELINE_NAME: MR pipeline for '$CI_MERGE_REQUEST_SOURCE_BRANCH_NAME'
        # for tags
    - if: $CI_COMMIT_TAG
      variables:
        FOUR_C_PIPELINE_NAME: Tag pipeline for '$CI_COMMIT_TAG'
        # for a merge to the default branch
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      variables:
        FOUR_C_PIPELINE_NAME: Post-merge pipeline for '$CI_COMMIT_TITLE'
    - if: $CI_PIPELINE_SOURCE == "schedule" && $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      variables:
        FOUR_C_PIPELINE_NAME: Scheduled pipeline for '$CI_COMMIT_TITLE'
        # if manually triggered with the web interface's "run pipeline"
    - if: $CI_PIPELINE_SOURCE == "web"
      variables:
        FOUR_C_PIPELINE_NAME: Manual pipeline for '$CI_COMMIT_BRANCH'

#-------------------------------------------------------------------------------
# Define global variables for all jobs
variables:
  # Clone repository by default, file have changed attribute.
  GIT_STRATEGY: clone

  GITLAB_PIPELINE_TYPE:
    value: default
    description: Type of pipeline
    options: [default, nightly, coverage, trilinos develop]

  # Variables for docker
  # Whether to build the docker images and push them to the CI registry
  FOUR_C_DOCKER_BUILD_IMAGES: 'False'
  FOUR_C_DOCKER_DEPENDENCIES_HASH: da17023e
  FOUR_C_DOCKER_DEPENDENCIES_IMAGE: 4c-dependencies
  FOUR_C_DOCKER_DEPENDENCIES_IMAGE_WITH_HASH: $FOUR_C_DOCKER_DEPENDENCIES_IMAGE:$FOUR_C_DOCKER_DEPENDENCIES_HASH

  # Variables for Trilinos pipeline
  # The default Trilinos commit ref the Trilinos pipeline is running on
  TRILINOS_PIPELINE_COMMIT_REF: develop
  FOUR_C_DOCKER_DEPENDENCIES_IMAGE_TRILINOS: 4c-dependencies-trilinos:$TRILINOS_PIPELINE_COMMIT_REF

.compute_dependencies_hash: &compute_dependencies_hash
  # compute short hash from contents of folder dependencies and docker (exclude trilinos_config and README.md files)
  - COMPUTED_DOCKER_DEPENDENCIES_HASH=`find dependencies docker -not -wholename '*/trilinos_develop/*'
    -not -name 'README.md' -type f -exec sha1sum {} \; | sort | sha1sum | cut -c -8`

before_script:
  - git config --global --add safe.directory ${CI_PROJECT_DIR}
  - *compute_dependencies_hash
  - if [ "${COMPUTED_DOCKER_DEPENDENCIES_HASH}" != "$FOUR_C_DOCKER_DEPENDENCIES_HASH" ]; then echo "Docker
    image version hash does not match the hash of the dependencies. You likely need to change the hash
    to ${COMPUTED_DOCKER_DEPENDENCIES_HASH} and rebuild the dependencies." && exit 1; else echo "Running
    on the correct docker image version with hash $FOUR_C_DOCKER_DEPENDENCIES_HASH."; fi

.clean-build-folder-for-nightly-pipelines: &clean-build-folder-for-nightly-pipelines
  # Delete build folder for a clean build for the nightly pipeline
  - if [ $GITLAB_PIPELINE_TYPE == "nightly" ]; then echo "Removing build folder"; rm -rf ${CI_PROJECT_DIR}/../build/;
    fi

.build-only: &build-only
  - mkdir -p ${CI_PROJECT_DIR}/../build
  # configure
  - |
    cd ${CI_PROJECT_DIR}
    ./utilities/set_up_dev_env.sh
    cd ${CI_PROJECT_DIR}/../build
    cmake ${CI_PROJECT_DIR} --fresh --preset=${CMAKE_PRESET}
  - echo Building the following targets ${BUILD_TARGETS}
  # build
  - time cmake --build . --target ${BUILD_TARGETS} -- -j `nproc` 2>&1 | tee ${CI_PROJECT_DIR}/build.log

.build-and-test: &build-and-test
  - *build-only
  # test
  - time ctest -VV -j `nproc` --output-junit ${CI_PROJECT_DIR}/junit_test_summary.xml | tee ${CI_PROJECT_DIR}/test.log
    | grep -e "\*\*\*Failed" -e "\.\.\.   Passed" -e " tests passed\,"
  - cd ${CI_PROJECT_DIR}

.post_process_log_files: &post_process_log_files
  # sort output of pipeline
  - cd ${CI_PROJECT_DIR}/../build
  - ${CI_PROJECT_DIR}/utilities/python-venv/bin/python ${CI_PROJECT_DIR}/utilities/sort_pipeline_output.py
    ${CI_PROJECT_DIR}/test.log ${CI_PROJECT_DIR}/test.log
  # Write selection of the output into the terminal and therefore to GITLAB
  # Output 200 lines for any failing test
  - grep -B 200 '*Failed\|*Timeout' ${CI_PROJECT_DIR}/test.log || true
  - sed -n '/tests passed,/,//p' ${CI_PROJECT_DIR}/test.log
  # Move the log files to the source folder, so it can be found by artifacts.
  - cd ${CI_PROJECT_DIR}

# Generic job that builds and tests the project. Derived jobs may configure the details via variables.
.buildtest_base:
  stage: buildtest
  variables:
    # So the old build can be used again.
    GIT_STRATEGY: fetch
    BUILD_TARGETS: full
  script:
    - *clean-build-folder-for-nightly-pipelines
    - *build-and-test
  after_script:
    - *post_process_log_files
  artifacts:
    name: $CI_JOB_NAME-$CI_JOB_ID
    paths:
      - '*.log'
      - junit_test_summary.xml
    reports:
      junit: junit_test_summary.xml
    when: always
    expire_in: 1 day

#-------------------------------------------------------------------------------
# Stages during testing.
#-------------------------------------------------------------------------------

# We use stages just for grouping jobs into different categories. Dependencies are defined using the
# `needs` keyword to reduce the time of a pipeline run, see the Gitlab documentation about Directed
# Acyclic Graph Pipelines (https://docs.gitlab.com/ee/ci/pipelines/pipeline_architectures.html#directed-acyclic-graph-pipelines).
stages:
  - build-docker-images
  - checkcode
  - buildtest
  - documentation
  - pages

# Check for code style
checkcode:
  stage: checkcode
  image: $CI_REGISTRY_IMAGE/$FOUR_C_DOCKER_DEPENDENCIES_IMAGE_WITH_HASH
  script:
    - echo code check
    - ./utilities/set_up_dev_env.sh
    # Special check for code owner rules: this check runs differently in CI since we want to check that every rule
    # matches at least one file. This is not the feasible in the normal pre-commit check.
    - bash utilities/code_checks/check_code_owner_rules
    # Run pre-commit checks without caches on all files
    - source ./utilities/python-venv/bin/activate
    - pre-commit clean
    - pre-commit run --all-files --show-diff-on-failure
  artifacts:
    name: $CI_JOB_NAME-$CI_JOB_ID
    paths:
      - wrong_*.txt
    when: on_failure
    expire_in: 1 day
  rules:
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
    - if: $CI_PIPELINE_SOURCE == "web"
    - if: $GITLAB_PIPELINE_TYPE == "nightly"
  tags:
    - checkcode
  interruptible: true
  needs:
    - job: build_base_dependencies
      optional: true

# Include a pre-configured danger bot job at a fixed version. Verbatim copy of:
# https://gitlab.com/gitlab-org/quality/pipeline-common/-/raw/7.5.1/ci/danger-review.yml
#
# This job supports the following variables:
# - DANGER_GITLAB_API_TOKEN: (Optional) A project access token with `api` scope.
# - GITLAB_DANGERFILES_VERSION: (Optional) Version requirement for `gitlab-dangerfiles`. Latest version if empty.
danger_review:
  image: ruby:3.0
  stage: checkcode
  tags:
    - danger
  interruptible: true
  needs: []
  retry:
    max: 2
    when:
      - unknown_failure
      - api_failure
      - runner_system_failure
      - stuck_or_timeout_failure
  before_script:
    - bundle install --gemfile="./utilities/danger/Gemfile"
    - apt-get update && apt-get install -y python3-venv
    # create  and activate virtual environment
    - python3 -m venv venv
    - . venv/bin/activate
    - pip install wheel
    - pip install -r ${CI_PROJECT_DIR}/utilities/danger/requirements.txt
  script:
    - |
      danger_id=$(echo -n ${DANGER_GITLAB_API_TOKEN} | md5sum | awk '{print $1}' | cut -c5-10);
      BUNDLE_GEMFILE=./utilities/danger/Gemfile bundle exec danger --fail-on-errors=true --verbose --danger_id="${danger_id}" --dangerfile="./utilities/danger/Dangerfile";
  rules:
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'

# Docker---------------------------------------------------------------------------

codeclimate:
  stage: checkcode
  image: $CI_REGISTRY_IMAGE/$FOUR_C_DOCKER_DEPENDENCIES_IMAGE_WITH_HASH
  script:
    - *clean-build-folder-for-nightly-pipelines
    - mkdir -p ${CI_PROJECT_DIR}/../build && cd ${CI_PROJECT_DIR}/../build
    # configure to get a compilation database: use a unity build for faster parsing of files
    - cmake ${CI_PROJECT_DIR} --fresh -DCMAKE_CXX_COMPILER="clang++" -DFOUR_C_BUILD_READTHEDOCS=OFF -DCMAKE_UNITY_BUILD=ON
      --preset=docker_codeclimate
    # create and activate virtual environment
    - python3 -m venv venv
    - . venv/bin/activate
    - pip install wheel
    - pip install -r ${CI_PROJECT_DIR}/utilities/code_climate/requirements.txt
    # create temporary directory for the yaml files from clang-tidy
    - mkdir clang-tidy-issues
    - ESCAPED_PROJECT_DIR=$(echo "${CI_PROJECT_DIR}" | sed 's/\//\\\//g')
    # run clang tidy and export report
    - run-clang-tidy -j `nproc` -config-file ${CI_PROJECT_DIR}/.clang-tidy -use-color -p . -export-fixes
      ./clang-tidy-issues/ -header-filter "${ESCAPED_PROJECT_DIR}\/.*" 2>&1 | python ${CI_PROJECT_DIR}/utilities/code_climate/filter_clang_tidy_output.py
    # export clang tidy issues
    - python ${CI_PROJECT_DIR}/utilities/code_climate/export_clang_tidy_issues.py -j `nproc` --code-climate-file
      ${CI_PROJECT_DIR}/codeclimate.json --source-folder ${CI_PROJECT_DIR} ./clang-tidy-issues/*.yaml
    - cd ${CI_PROJECT_DIR}
  artifacts:
    paths: [codeclimate.json]
    reports:
      codequality: codeclimate.json
  tags:
    - codeclimate
  needs:
    - job: build_base_dependencies
      optional: true
  interruptible: true
  # Always run this job, no rules needed.

# Full tests with coverage are performed and a coverage report is created
buildtest_coverage:
  stage: buildtest
  image: $CI_REGISTRY_IMAGE/$FOUR_C_DOCKER_DEPENDENCIES_IMAGE_WITH_HASH
  variables:
    BUILD_TARGETS: full
    # enable coverage option of ctest
    CMAKE_PRESET: docker_coverage
  script:
    - *clean-build-folder-for-nightly-pipelines
    - *build-and-test
    # generate the coverage_base.info: the "baseline" coverage data file that contains zero coverage for every instrumented line.
    - lcov --capture --initial --no-external --directory ../build/ --base-directory . --output-file coverage_base.info
      > ${CI_PROJECT_DIR}/coverage_base.log
    # generate the coverage_tests.info based on tests run above
    - lcov --capture --no-external --directory ../build/ --base-directory . --output-file coverage_tests.info
      > ${CI_PROJECT_DIR}/coverage_tests.log
    # combine the baseline coverage with the coverage from the tests
    - lcov --add-tracefile coverage_base.info --add-tracefile coverage_tests.info --output-file coverage.info  >
      ${CI_PROJECT_DIR}/coverage.log
    # remove unwanted files from the coveragre report
    - lcov --remove coverage.info "*/unittests*/*" "*/tests/*" "*/build/*" -o coverage_filtered.info >
      ${CI_PROJECT_DIR}/coverage_filtered.log
    # generate the html version of the coverage report
    - genhtml coverage_filtered.info --legend --demangle-cpp --output-directory coverage_report/ --title
      "4C commit $CI_COMMIT_SHORT_SHA" | tee ${CI_PROJECT_DIR}/genhtml_coverage.log
    # add repo link to the commit that the report is based on
    - find coverage_report/ -type f -exec sed -i "s/4C commit $CI_COMMIT_SHORT_SHA/4C commit  \<a href=\"https:\/\/gitlab.lrz.de\/baci\/baci\/commit\/$CI_COMMIT_SHA\"\>$CI_COMMIT_SHORT_SHA\<\/a\>/g"
      {} \;
  after_script:
    - *post_process_log_files
  artifacts:
    name: $CI_JOB_NAME-$CI_JOB_ID
    paths:
      - '*.log'
      - coverage_report/
    when: always
    expire_in: 30 days
  rules:
    - if: $GITLAB_PIPELINE_TYPE == "coverage"
  tags:
    - coverage
  needs: []

pages: # job name needs to be pages
  stage: pages
  image: alpine:3.18
  # Download Doxygen and ReadTheDocs from previous documentation stage
  needs:
    - job: build_base_dependencies
      optional: true
    - job: doxygen
      artifacts: true
    - job: readthedocs
  before_script: []
  script:
    # Create python venv for gitlab api and anybadges
    - apk add python3 curl unzip git
    - python3 -m venv venv
    - . venv/bin/activate
    - pip install -r utilities/coverage/requirements.txt
    # Download latest coverage report
    - LATEST_ARTIFACT_URL="`python ./utilities/coverage/get_latest_artifacts_url_by_jobname.py $CI_SERVER_URL
      $ACCESS_TOKEN $CI_PROJECT_ID $CI_DEFAULT_BRANCH buildtest_coverage`"
    - 'curl --location --output coverage_artifacts.zip --header "PRIVATE-TOKEN: $ACCESS_TOKEN" "$LATEST_ARTIFACT_URL"'
    - unzip coverage_artifacts.zip -d coverage_artifacts
    # Print measured coverage rate
    - grep "Overall coverage rate:" -A 2 coverage_artifacts/genhtml_coverage.log
    # Create directory that will be published
    - mkdir -p public
    # move created coverage report to public folder (which is the path for GitLab Pages content)
    - mv coverage_artifacts/coverage_report public/coverage_report
    # Move most recent doxygen to public folder
    - mv doxygen public/doxygen
    # Move most recent readthedocs to public folder
    - mv readthedocs public/readthedocs
    - pip install anybadge
    # Create doxygen badge
    - anybadge -l doxygen -v ok --color=green -f public/doxygen.svg
    # Create readthedocs badge
    - anybadge -l readthedocs -v ok --color=green -f public/readthedocs.svg
    # Create website badge
    - anybadge -l website -v ok --color=green -f public/website.svg
    # Create performance report
    - anybadge -l performance -v report --color=cornflowerblue -f public/performance.svg
  coverage: /lines\.*:\s+\d+\.\d+/
  artifacts:
    # store the public path in artifact
    # this is needed since in a subsequent deploy stage (automatically generated by GitLab)
    # the content of the below artifact is published on GitLab Pages
    paths:
      - public
    expire_in: 1 day
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
  tags:
    - pages

doxygen:
  stage: documentation
  image: $CI_REGISTRY_IMAGE/$FOUR_C_DOCKER_DEPENDENCIES_IMAGE_WITH_HASH
  script:
    - echo Doxygen
    - *clean-build-folder-for-nightly-pipelines
    - mkdir -p ${CI_PROJECT_DIR}/../build && cd ${CI_PROJECT_DIR}/../build

    # Configure and build (setting FOUR_C_BUILD_READTHEDOCS=OFF, so that we don't need the python virtual environment
    - cmake ${CI_PROJECT_DIR} --fresh --preset=docker -DFOUR_C_BUILD_READTHEDOCS=OFF
    - cmake --build . --target doxygen > ${CI_PROJECT_DIR}/doxygen.log

    # Throw error if there are Latex errors in doxygen comments. Latex errors can be uniquely identified by a line starting with "! ".
    - if grep -qE '^[eE]rror:' ${CI_PROJECT_DIR}/doxygen.log; then echo 'Found at least one fatal error
      during doxygen generation.'; exit 1; else echo 'Doxygen builds without fatal errors.'; fi
    - if grep -qE '^! ' ${CI_PROJECT_DIR}/doxygen.log; then echo "Found at least one LaTeX error during
      doxygen build."; exit 1; else echo "Doxygen builds without LaTeX errors."; fi
    # Move final doxygen into the base folder for the next stage
    - mv $CI_PROJECT_DIR/../build/doc/doxygen/html $CI_PROJECT_DIR/doxygen
  after_script:
    # Write Selection of the output into the terminal and therefore to GITLAB
    - sed -n '/* Extra verbosity turned on/,/Test project /p' ${CI_PROJECT_DIR}/doxygen.log
    # Write information about possible Latex errors to terminal
    - if grep -qE '^! ' ${CI_PROJECT_DIR}/doxygen.log; then echo "Found at least one LaTeX error during
      doxygen build."; else echo "Doxygen builds without LaTeX errors."; fi
  tags:
    - doxygen
  artifacts:
    name: $CI_JOB_NAME-$CI_JOB_ID
    paths:
      - doxygen/
      - doxygen.log
    when: always
    expire_in: 1 day
  interruptible: true
  needs:
    - job: build_base_dependencies
      optional: true
      # Always run this job, no rules needed.

# Build the docker image with all dependencies for 4C
build_base_dependencies:
  stage: build-docker-images
  tags:
    - build-docker-image
  image: docker:20.10.16
  services:
    - docker:20.10.16-dind
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - *compute_dependencies_hash
    - echo $CI_REGISTRY_IMAGE
    - echo $CI_REGISTRY
    - echo "Generating 4C dependencies docker image with version-hash $COMPUTED_DOCKER_DEPENDENCIES_HASH"
    - FULL_IMAGE_PATH="$CI_REGISTRY_IMAGE/$FOUR_C_DOCKER_DEPENDENCIES_IMAGE:$COMPUTED_DOCKER_DEPENDENCIES_HASH"
    - docker build --no-cache --tag $FULL_IMAGE_PATH --file docker/Dockerfile .
    - docker push $FULL_IMAGE_PATH
  rules:
    - if: $FOUR_C_DOCKER_BUILD_IMAGES == "True"
      when: manual

gcc9:
  extends: .buildtest_base
  image: $CI_REGISTRY_IMAGE/$FOUR_C_DOCKER_DEPENDENCIES_IMAGE_WITH_HASH
  variables:
    CMAKE_PRESET: docker
  tags:
    - buildtest
  needs:
    - job: build_base_dependencies
      optional: true
  rules:
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
    - if: $CI_PIPELINE_SOURCE == "web"
    - if: $GITLAB_PIPELINE_TYPE == "nightly"
  interruptible: true

gcc9_asan:
  extends: .buildtest_base
  image: $CI_REGISTRY_IMAGE/$FOUR_C_DOCKER_DEPENDENCIES_IMAGE_WITH_HASH
  variables:
    CMAKE_PRESET: docker_asan
  after_script:
    - *post_process_log_files
    - ${CI_PROJECT_DIR}/utilities/grep_asan_failures.sh ${CI_PROJECT_DIR}/test.log > ${CI_PROJECT_DIR}/asan_summary.log
  tags:
    - buildtest
  needs:
    - job: build_base_dependencies
      optional: true
  rules:
    - if: $GITLAB_PIPELINE_TYPE == "nightly"
  interruptible: true

gcc14_assertions:
  extends: .buildtest_base
  image: $CI_REGISTRY_IMAGE/$FOUR_C_DOCKER_DEPENDENCIES_IMAGE_WITH_HASH
  variables:
    CMAKE_PRESET: docker_release_assertions_gcc14
  tags:
    - buildtest
  needs:
    - job: build_base_dependencies
      optional: true
  rules:
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
    - if: $CI_PIPELINE_SOURCE == "web"
    - if: $GITLAB_PIPELINE_TYPE == "nightly"
  interruptible: true

clang18:
  extends: .buildtest_base
  image: $CI_REGISTRY_IMAGE/$FOUR_C_DOCKER_DEPENDENCIES_IMAGE_WITH_HASH
  variables:
    CMAKE_PRESET: docker_release_clang18
  tags:
    - buildtest
  needs:
    - job: build_base_dependencies
      optional: true
  rules:
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
    - if: $CI_PIPELINE_SOURCE == "web"
    - if: $GITLAB_PIPELINE_TYPE == "nightly"
  interruptible: true

verify_headers:
  image: $CI_REGISTRY_IMAGE/$FOUR_C_DOCKER_DEPENDENCIES_IMAGE_WITH_HASH
  variables:
    NUMBER_OF_BUILD_THREADS: '10'
  tags:
    - verify-headers
  needs:
    - job: build_base_dependencies
      optional: true
  stage: checkcode
  script:
    - *clean-build-folder-for-nightly-pipelines
    - mkdir -p ${CI_PROJECT_DIR}/../build
    # configure
    - |
      cd ${CI_PROJECT_DIR}
      ./utilities/set_up_dev_env.sh
      cd ${CI_PROJECT_DIR}/../build
      # Configure verification of header sets.
      cmake ${CI_PROJECT_DIR} --fresh --preset=docker -DCMAKE_VERIFY_INTERFACE_HEADER_SETS="ON"
      # verify headers
    - time cmake --build . --target all_verify_interface_header_sets -- -j `nproc` 2>&1 | tee ${CI_PROJECT_DIR}/verify_headers.log
  artifacts:
    name: $CI_JOB_NAME-$CI_JOB_ID
    paths:
      - '*.log'
    when: on_failure
    expire_in: 1 day
  rules:
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
    - if: $CI_PIPELINE_SOURCE == "web"
    - if: $GITLAB_PIPELINE_TYPE == "nightly"
  interruptible: true

readthedocs:
  stage: documentation
  image: $CI_REGISTRY_IMAGE/$FOUR_C_DOCKER_DEPENDENCIES_IMAGE_WITH_HASH
  script:
    - echo Create ReadTheDocs documentation
    # loading python virtual environment
    - cd ${CI_PROJECT_DIR}
    - ./utilities/set_up_dev_env.sh
    - *clean-build-folder-for-nightly-pipelines
    - mkdir -p ${CI_PROJECT_DIR}/../build && cd ${CI_PROJECT_DIR}/../build

    # Configure and build
    - cmake ${CI_PROJECT_DIR} --fresh --preset=docker
    - cmake --build . --target readthedocs | tee ${CI_PROJECT_DIR}/readthedocs.log

    # Throw error if there are errors (or Warnings treated as errors) in readthedocs comments.
    - if grep -qE 'ERROR|treated as error:' ${CI_PROJECT_DIR}/readthedocs.log; then echo 'Found at least
      one fatal error during readthedocs generation.'; exit 1; else echo 'ReadTheDocs documentation builds
      without fatal errors.'; fi
    # Move final readthedocs into the base folder for the next stage
    - mv $CI_PROJECT_DIR/../build/doc/readthedocs/html $CI_PROJECT_DIR/readthedocs
  after_script:
    # Write Selection of the output into the terminal and therefore to GITLAB
    - sed -n '/* Extra verbosity turned on/,/Test project /p' ${CI_PROJECT_DIR}/readthedocs.log
  tags:
    - readthedocs
  artifacts:
    name: $CI_JOB_NAME-$CI_JOB_ID
    paths:
      - readthedocs/
      - readthedocs.log
    when: always
    expire_in: 1 day
  interruptible: true
  needs:
    - job: build_base_dependencies
      optional: true
      # Always run this job, no rules needed.

# The Trilinos pipeline with a specific commit ref runs via a schedule or when manually triggered
build_base_dependencies_trilinos_develop:
  stage: build-docker-images
  tags:
    - build-docker-image
  image: docker:20.10.16
  services:
    - docker:20.10.16-dind
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - echo "Generating 4C dependencies docker image with Trilinos version $TRILINOS_PIPELINE_COMMIT_REF"
    - FULL_IMAGE_PATH="$CI_REGISTRY_IMAGE/$FOUR_C_DOCKER_DEPENDENCIES_IMAGE_TRILINOS"
    - docker build --no-cache --build-arg NPROCS=`nproc` --build-arg TRILINOS_VERSION="$TRILINOS_PIPELINE_COMMIT_REF"
      --tag $FULL_IMAGE_PATH --file docker/trilinos_develop/Dockerfile .
    - docker push $FULL_IMAGE_PATH
  rules:
    - if: $GITLAB_PIPELINE_TYPE == "trilinos develop"
  interruptible: true

gcc9_trilinos_develop:
  extends: .buildtest_base
  image: $CI_REGISTRY_IMAGE/$FOUR_C_DOCKER_DEPENDENCIES_IMAGE_TRILINOS
  variables:
    CMAKE_PRESET: docker
  tags:
    - buildtest
  needs:
    - job: build_base_dependencies_trilinos_develop
      optional: true
  rules:
    - if: $GITLAB_PIPELINE_TYPE == "trilinos develop"
  interruptible: true

gcc9_assertions_trilinos_develop:
  extends: .buildtest_base
  image: $CI_REGISTRY_IMAGE/$FOUR_C_DOCKER_DEPENDENCIES_IMAGE_TRILINOS
  variables:
    CMAKE_PRESET: docker_release_assertions
  tags:
    - buildtest
  needs:
    - job: build_base_dependencies_trilinos_develop
      optional: true
  rules:
    - if: $GITLAB_PIPELINE_TYPE == "trilinos develop"
  interruptible: true
